{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "crude-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as kr\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers import CRF\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "industrial-linux",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-c45f27cdde2f>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    }
   ],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "    BATCH_SIZE = 512  # Number of examples used in each iteration\n",
    "    EPOCHS = 5  # Number of passes through entire dataset\n",
    "    MAX_LEN = 75  # Max length of review (in words)\n",
    "    EMBEDDING = 40  # Dimension of word embedding vector\n",
    "\n",
    "    \n",
    "# Hyperparams for CPU training\n",
    "else:\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 5\n",
    "    MAX_LEN = 75\n",
    "    EMBEDDING = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "signed-delivery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences:  47959\n",
      "Number of words in the dataset:  35178\n",
      "Tags: ['B-nat', 'B-org', 'B-art', 'B-tim', 'I-per', 'I-gpe', 'I-tim', 'I-eve', 'O', 'B-gpe', 'B-eve', 'I-geo', 'B-geo', 'I-art', 'I-nat', 'B-per', 'I-org']\n",
      "Number of Labels:  17\n",
      "What the dataset looks like:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS    Tag\n",
       "0  Sentence: 1      Thousands  NNS      O\n",
       "1  Sentence: 1             of   IN      O\n",
       "2  Sentence: 1  demonstrators  NNS      O\n",
       "3  Sentence: 1           have  VBP      O\n",
       "4  Sentence: 1        marched  VBN      O\n",
       "5  Sentence: 1        through   IN      O\n",
       "6  Sentence: 1         London  NNP  B-geo\n",
       "7  Sentence: 1             to   TO      O\n",
       "8  Sentence: 1        protest   VB      O\n",
       "9  Sentence: 1            the   DT      O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\")\n",
    "data = data.fillna(method=\"ffill\")\n",
    "\n",
    "print(\"Number of sentences: \", len(data.groupby(['Sentence #'])))\n",
    "\n",
    "words = list(set(data[\"Word\"].values))\n",
    "n_words = len(words)\n",
    "print(\"Number of words in the dataset: \", n_words)\n",
    "\n",
    "tags = list(set(data[\"Tag\"].values))\n",
    "print(\"Tags:\", tags)\n",
    "n_tags = len(tags)\n",
    "print(\"Number of Labels: \", n_tags)\n",
    "\n",
    "print(\"What the dataset looks like:\")\n",
    "# Show the first 10 rows\n",
    "data.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cathedral-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is what a sentence looks like:\n",
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "class SentenceGetter(object):\n",
    "    \"\"\"Class to Get the sentence in this format:\n",
    "    [(Token_1, Part_of_Speech_1, Tag_1), ..., (Token_n, Part_of_Speech_1, Tag_1)]\"\"\"\n",
    "    def __init__(self, data):\n",
    "        \"\"\"Args:\n",
    "            data is the pandas.DataFrame which contains the above dataset\"\"\"\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        \"\"\"Return one sentence\"\"\"\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "getter = SentenceGetter(data)\n",
    "sent = getter.get_next()\n",
    "print('This is what a sentence looks like:')\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "elder-fighter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get all the sentences\n",
    "sentences = getter.sentences\n",
    "\n",
    "# Plot sentence by lenght\n",
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.title('Token per sentence')\n",
    "plt.xlabel('Len (number of token)')\n",
    "plt.ylabel('# samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "junior-cancellation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word Obama is identified by the index: 7085\n",
      "The labels B-geo(which defines Geopraphical Enitities) is identified by the index: 13\n",
      "Raw Sample:  Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
      "Raw Label:  O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\n",
      "After processing, sample: [ 3526  3735 17487 23146 13475 11171  6392 33884   110 19288 17972 16849\n",
      " 26749 11510  8663 19288  3501  3735  6003  5758  5993  5130  7079 22446\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0]\n",
      "After processing, labels: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary Key:word -> Value:token_index\n",
    "# The first 2 entries are reserved for PAD and UNK\n",
    "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
    "word2idx[\"UNK\"] = 1 # Unknown words\n",
    "word2idx[\"PAD\"] = 0 # Padding\n",
    "\n",
    "# Vocabulary Key:token_index -> Value:word\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "\n",
    "# Vocabulary Key:Label/Tag -> Value:tag_index\n",
    "# The first entry is reserved for PAD\n",
    "tag2idx = {t: i+1 for i, t in enumerate(tags)}\n",
    "tag2idx[\"PAD\"] = 0\n",
    "\n",
    "# Vocabulary Key:tag_index -> Value:Label/Tag\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "print(\"The word Obama is identified by the index: {}\".format(word2idx[\"Obama\"]))\n",
    "print(\"The labels B-geo(which defines Geopraphical Enitities) is identified by the index: {}\".format(tag2idx[\"B-geo\"]))\n",
    "\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# Convert each sentence from list of Token to list of word_index\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "# Padding each sentence to have the same lenght\n",
    "X = pad_sequences(maxlen=MAX_LEN, sequences=X, padding=\"post\", value=word2idx[\"PAD\"])\n",
    "\n",
    "# Convert Tag/Label to tag_index\n",
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "# Padding each sentence to have the same lenght\n",
    "y = pad_sequences(maxlen=MAX_LEN, sequences=y, padding=\"post\", value=tag2idx[\"PAD\"])\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "# One-Hot encode\n",
    "y = [to_categorical(i, num_classes=n_tags+1) for i in y]  # n_tags+1(PAD)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)\n",
    "X_tr.shape, X_te.shape, np.array(y_tr).shape, np.array(y_te).shape\n",
    "\n",
    "print('Raw Sample: ', ' '.join([w[0] for w in sentences[0]]))\n",
    "print('Raw Label: ', ' '.join([w[2] for w in sentences[0]]))\n",
    "print('After processing, sample:', X[0])\n",
    "print('After processing, labels:', y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aquatic-alpha",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cage/.local/lib/python3.8/site-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
      "  warnings.warn('CRF.loss_function is deprecated '\n",
      "/home/cage/.local/lib/python3.8/site-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
      "  warnings.warn('CRF.accuracy is deprecated and it '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"time_distributed/Reshape_1:0\", shape=(None, 75, 50), dtype=float32)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 75)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 75, 20)            703600    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 75, 100)           28400     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 75, 50)            5050      \n",
      "_________________________________________________________________\n",
      "crf (CRF)                    (None, 75, 18)            1278      \n",
      "=================================================================\n",
      "Total params: 738,328\n",
      "Trainable params: 738,328\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "input = Input(shape=(MAX_LEN,))\n",
    "model = Embedding(input_dim=n_words+2, output_dim=EMBEDDING, # n_words + 2 (PAD & UNK)\n",
    "                  input_length=MAX_LEN, mask_zero=True)(input)  # default: 20-dim embedding\n",
    "model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                           recurrent_dropout=0.1))(model)  # variational biLSTM\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "#model.add(tf.keras.layers.Reshape((1,75,50), input_shape=(None, 75, 50)))\n",
    "crf = CRF(n_tags+1)  # CRF layer, n_tags+1(PAD)\n",
    "out = crf(model)  # output\n",
    "\n",
    "model = Model(input, out)\n",
    "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "from IPython.display import Image \n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "Image('model_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cross-basis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38846 samples, validate on 4317 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Can not squeeze dim[0], expected a dimension of 1, got 32\n\t [[{{node metrics/crf_viterbi_accuracy/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_bool_Squeeze_1}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-304506222eef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(X_tr, np.array(y_tr), batch_size=BATCH_SIZE, epochs=EPOCHS,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     validation_split=0.1, verbose=2)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m     return func.fit(\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m       \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m     return fit_loop(\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3954\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3956\u001b[0;31m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[1;32m   3957\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[1;32m   3958\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Can not squeeze dim[0], expected a dimension of 1, got 32\n\t [[{{node metrics/crf_viterbi_accuracy/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_bool_Squeeze_1}}]]"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, np.array(y_tr), batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "                    validation_split=0.1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-somalia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
